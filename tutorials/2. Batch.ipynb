{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seismic CropBatch tutorial\n",
    "\n",
    "Welcome! This notebook shows how to use `SeismicCropBatch` to load data from cubes, create segmentation masks from labels, and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary modules\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('..')\n",
    "from seismiqb.batchflow import FilesIndex\n",
    "from seismiqb.batchflow import D, P, R\n",
    "from seismiqb import SeismicCropBatch, SeismicGeometry, SeismicCubeset\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all, we create `SeismicCubeset`\n",
    "To learn more what it is all about, check out our previous tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_0 = '/notebooks/SEISMIC_DATA/CUBE_1/E_anon.hdf5'\n",
    "path_data_1 = '/notebooks/SEISMIC_DATA/CUBE_3/P_cube.hdf5'\n",
    "path_data_2 = '/notebooks/SEISMIC_DATA/CUBE_VUONGMK/Repaired_cube.hdf5'\n",
    "\n",
    "dsi = FilesIndex(path=[path_data_0, path_data_1, path_data_2], no_ext=True)\n",
    "ds = SeismicCubeset(dsi)\n",
    "\n",
    "ds = (ds.load_geometries()\n",
    "        .load_point_clouds(load_from = path_pc_saved)\n",
    "        .load_labels()\n",
    "        .load_samplers(p=[0.4, 0.2, 0.4])\n",
    "      )\n",
    "\n",
    "# ~80 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create batch\n",
    "\n",
    "* First action, `load_component`, creates references to geometries and labels in instance of `SeismicCropBatch`. That is done for convinience and ease of access of these entities.\n",
    "\n",
    "* Then we use `crop`. It creates positions to cut crops of desired shape from cubes. Note that it does not load anything from disk: only positions are created.\n",
    "\n",
    "* Heavy lifting of disk I/O is performed by `load_cubes`, that takes positions (created by `crop`) and actually gets data from cube.\n",
    "\n",
    "* `create_masks` creates segmentation mask of the same size as cutted crop from `labels` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_batch = (ds.p.load_component(src=[D('geometries'), D('labels')],\n",
    "                                  dst=['geometries', 'labels'])\n",
    "                  .crop(points=L(ds.sampler.sample, 16), shape=[3, 512, 512])\n",
    "                  .load_cubes(dst='data_crops')\n",
    "                  .create_masks(dst='mask_crops')\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check contents of `data_crops` and `mask_crops` components of batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cube in np.random.choice(16, 2):\n",
    "    print(demo_batch.indices[cube][:-10])\n",
    "    iline = 0\n",
    "    \n",
    "    img = demo_batch.data_crops[cube][iline, :, :].T\n",
    "    mask = demo_batch.mask_crops[cube][iline, :, :].T\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(25, 10))\n",
    "\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].set_title('Cube slice')\n",
    "    \n",
    "    ax[1].imshow(masks, cmap=\"Blues\")\n",
    "    ax[1].imshow(img, cmap=\"gray\", alpha=0.5)\n",
    "    ax[1].imshow(masks, cmap=\"Blues\", alpha=0.1)\n",
    "    ax[1].set_title('Mask')\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add some data augmentations:\n",
    "* `rotate_axis.` By default, `crop`, `load_cubes`, `create_mask` work in [iline, xline, h] format. That might be inconvenient to work with, as most of our models percieve that 3D entity as 2D entity with multiple channels. This action makes order [xline, h, iline].\n",
    "* `add_axis.` Again, if model works with 3D entity via 2D convolutions, it needs one additional dimension added to the output in order to correctly compute loss between NN-output and reference segmentation mask.\n",
    "* `scale.` As different cubes have different ranges of possible values, it is usually a good idea to transform each of them to [0, 1] range. Under the hood, minimum and maximum values for each cube are used.\n",
    "* `additive_noise`, `multiplicative_noise.` Modify each entry in `src` by adding zero-mean noise or multiplying by values with mean at 1.\n",
    "\n",
    "#### All of the next actions are applied to the first two axes, so `rotate_axis` is what you want to do before them!\n",
    "* `rotate`, `scale_2d.` Rotate image around its center, zoom in or zoom out of it. \n",
    "* `cutout_2d`. Zero-out patches of first two axes.\n",
    "* `affine_transform`, `perspective_transform.` Change basis to move 3 (4 in case of perspective transform) points to different location. \n",
    "* `elastic_transform.` Slightly jitter the indexing grid of the first two axes of `src`. \n",
    "* `bandwidth_filter.` Keep only desired range of frequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "demo_pipeline = (Pipeline()\n",
    "                 .load_component(src=[D('geometries'), D('labels')],\n",
    "                                 dst=['geometries', 'labels'])\n",
    "                 .crop(points=L(ds.sampler.sample, 16), shape=[3, 256, 256])\n",
    "                 .load_cubes(fmt='h5py', dst='data_crops')\n",
    "                 .create_masks(dst='mask_crops')\n",
    "                 .scale(mode='normalize', src='data_crops')\n",
    "                 .rotate_axes(src=['data_crops', 'mask_crops'])\n",
    "                 .add_axis(src='mask_crops')\n",
    "                 # augmentations\n",
    "                 .additive_noise(scale=0.01, src='data_crops_anoise')\n",
    "                 .multiplicative_noise(scale=0.01, src='data_crops_mnoise')\n",
    "                 .cutout_2d(patch_shape=P(R('uniform', 10, 20, size=2)), n=P(R('uniform', 10, 20)),\n",
    "                            src='data_crops', dst='data_crops_cutout')\n",
    "                 .rotate(angle=0, src='data_crops', dst='data_crops_rotated')\n",
    "                 .scale_2d(scale=2, src='data_crops', dst='data_crops_scaled')\n",
    "                 .affine_transform(alpha_affine=P(R('uniform', 0, 30)),\n",
    "                                   src='data_crops', dst='data_crops_affine')\n",
    "                 .perspective_transform(alpha_persp=P(R('uniform', 0, 30)),\n",
    "                                        src='data_crops', dst='data_crops_perspective')\n",
    "                 .elastic_transform(alpha=40, sigma=4,\n",
    "                                    src='data_crops', dst='data_crops_elastic')\n",
    "                 .bandwidth_filter(lowcut=0.09, highcut=0.5, fs=2,\n",
    "                                   src='data_crops', dst='data_crops_filtered')\n",
    "                 ) << ds\n",
    "\n",
    "demo_batch = demo_pipeline.next_batch(3, n_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
