{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizonts detection model\n",
    "\n",
    "## Content\n",
    "\n",
    "* [Problem description](description)\n",
    "* [Dataset](dataset)\n",
    "* [Model architecture](architecture)\n",
    "* [Training](training)\n",
    "* [Validation](validation)\n",
    "* [Criticism](criticism)\n",
    "* [Conclusion](conclusion)\n",
    "* [Suggestions for improvements](suggestions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='description'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "Seismic horizon is a change in rock properties across a boundary between two layers of rock, particularly seismic velocity and density. Such changes are visible in seismic images, and could be automatically detected. Proposed model should do this by using convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We use multiple seismic cubes, in particular, Cube 1, Cube 3 and Cube VU_ONGMK. Detailed description of each cube, including sample images, is available [here](./../datasets/Horizonts_modelling.ipynb).\n",
    "\n",
    "Note that different propotions of sampled points are applied to each cube: approximately 40% from the first, 20% from the second, 40% from the third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('..')\n",
    "from seismiqb.batchflow import Pipeline, FilesIndex\n",
    "from seismiqb.batchflow import B, V, C, L, F, D, P, R\n",
    "from seismiqb.batchflow.models.tf import *\n",
    "from seismiqb.batchflow.models.tf.layers import conv_block\n",
    "from seismiqb import SeismicCropBatch, SeismicGeometry, SeismicCubeset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_0 = '/notebooks/SEISMIC_DATA/CUBE_1/E_anon.hdf5'\n",
    "path_data_1 = '/notebooks/SEISMIC_DATA/CUBE_3/P_cube.hdf5'\n",
    "path_data_2 = '/notebooks/SEISMIC_DATA/CUBE_VUONGMK/Repaired_cube.hdf5'\n",
    "\n",
    "path_pc_saved = '/notebooks/SEISMIC_DATA/SAVED/ANEW/point_clouds.dill'   # path_data: point_clouds\n",
    "\n",
    "dsi = FilesIndex(path=[path_data_0, path_data_1, path_data_2], no_ext=True)\n",
    "ds = SeismicCubeset(dsi)\n",
    "\n",
    "ds = (ds.load_geometries()\n",
    "        .load_point_clouds(load_from = path_pc_saved)\n",
    "        .load_labels()\n",
    "        .load_samplers(p=[0.4, 0.2, 0.4])\n",
    "      )\n",
    "# ~80 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='architecture'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture\n",
    "\n",
    "We use convonlutional neural network in `EncoderDecoder` fashion and train on crops of (256, 256, 2) size:\n",
    "* First of all, initial crop is downsampled twice along xlines/heights dimensions, effectively reducing resolution 4 times\n",
    "* Then, we encode crop by applying `inception_a_block` of Inception_v4 3 times with max-pooling in-between\n",
    "* `Inception_c_block` is applied at the bottleneck\n",
    "* Initial shape of the block is restored by transposed convolutions with ordinary convolutions+batchnorm+activation(ReLU) in-between\n",
    "\n",
    "Multiple things are worth noting. Most importantly, model percieves every crop (a 3-d entity) as sequence of 2-d images stacked one after the other, and every convolution that is used is 2D.\n",
    "Every max-pooling in the network is of size and stride 2, effectively halving the resolution of its inputs. To get precise definitions of `Inception` blocks, check [this](https://arxiv.org/pdf/1602.07261.pdf) paper.\n",
    "\n",
    "Technical note: in order to compute `Dice`-coefficient, we need to add axis both to the output of neural network and to initial labels. That is done via `predictions` callable in the first case and `add_axis` action in the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "EPOCHS = 1500\n",
    "NUM_CROPS = 64\n",
    "CROP_SHAPE = (2, 256, 256) # i, x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ED class is to ensure that `head` block does not `crop` its inputs. \n",
    "# For more on that, check the `head` method of EncoderDecoder\n",
    "class ED(EncoderDecoder):\n",
    "    @classmethod\n",
    "    def head(cls, inputs, targets, name='head', **kwargs):\n",
    "        kwargs = cls.fill_params('head', **kwargs)\n",
    "        with tf.variable_scope(name):\n",
    "            channels = cls.num_channels(targets)\n",
    "            x = conv_block(inputs, filters=channels, **kwargs)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ED config\n",
    "def predictions(x):\n",
    "    return tf.expand_dims(x, axis=-1, name='expand')\n",
    "\n",
    "model_config = {\n",
    "    'inputs': dict(cubes={'shape': (None, None, CROP_SHAPE[0])},\n",
    "                   masks={'name': 'targets', 'shape': (None, None, CROP_SHAPE[0], 1)}), \n",
    "    'initial_block/inputs': 'cubes',\n",
    "    'initial_block': {'layout': 'pp'},\n",
    "    'body/encoder': {'num_stages': 3,\n",
    "                     'blocks': {'base': Inception_v4.inception_a_block,\n",
    "                                'filters': [[32, 16], [48, 32], [64, 48]]}},\n",
    "    'body/embedding': {'base': Inception_v4.inception_c_block, 'filters': [32, 48, 64, 96]},\n",
    "    'body/decoder': {'num_stages': 5, 'blocks': {'layout':'cna', 'filters': [32, 16, 8, 6, 4]}},\n",
    "    'loss': 'dice',\n",
    "    'optimizer': 'Adam',\n",
    "    'predictions': predictions,\n",
    "    'output': 'sigmoid',\n",
    "    'common': {'data_format': 'channels_last'},\n",
    "    'microbatch': 32,\n",
    "}\n",
    "\n",
    "pipeline_config = {'model': ED,\n",
    "                   'model_config': model_config,\n",
    "                   'num_crops': NUM_CROPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='training'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Neural network is trained on crops of fixed shape. Pipeline consists of following steps:\n",
    "\n",
    "* First of all, we create positions of crops, then load actual data and labels for it\n",
    "* Then we scale values: that is done in order to equalize value ranges for different cubes\n",
    "* Right after, multiple augmentations are applied to simulate different distortions and make model robust to them\n",
    "* Model weights update\n",
    "\n",
    "Every batch contains 64 crops. Model is trained for 500 epochs with `Adam` optimizer with default parameters. Loss-function: `Dice`-coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (Pipeline(config=pipeline_config)\n",
    "                  .load_component(src=[D('geometries'), D('labels')],\n",
    "                                  dst=['geometries', 'labels'])\n",
    "                  .crop(points=L(ds.sampler.truncate(high=0.8, expr=lambda p: p[:, 1]).sample, NUM_CROPS), shape=CROP_SHAPE)\n",
    "                  .load_cubes(dst='data_crops')\n",
    "                  .create_masks(dst='mask_crops', width=1)\n",
    "                  .rotate_axes(src=['data_crops', 'mask_crops'])\n",
    "                  .scale(mode='normalize', src='data_crops')\n",
    "                  # Augmentations\n",
    "                  .additive_noise(scale=0.005, src='data_crops', dst='data_crops', p=0.2)\n",
    "                  .rotate(angle=P(R('uniform', -30, 30)), src=['data_crops', 'mask_crops'], p=0.4)\n",
    "                  .scale_2d(scale=P(R('uniform', 0.7, 1.3)), src=['data_crops', 'mask_crops'], p=0.4)\n",
    "                  .cutout_2d(patch_shape=P(R('uniform', 10, 30, size=2)), n=P(R('uniform', 3, 17)), src='data_crops', p=0.2)\n",
    "                  .elastic_transform(alpha=P(R('uniform', 35, 45)), sigma=P(R('uniform', 4, 4.5)),\n",
    "                                     src=['data_crops', 'mask_crops'], p=0.2)\n",
    "                  # Training\n",
    "                  .add_axis(src='mask_crops', dst='mask_crops')\n",
    "                  .init_variable('loss_history', init_on_each_run=list)\n",
    "                  .init_variable('current_loss')\n",
    "                  .init_model('dynamic', C('model'), 'ED', C('model_config'))\n",
    "                  .train_model('ED', \n",
    "                               fetches='loss', make_data={'cubes': B('data_crops'), 'masks': B('mask_crops')},\n",
    "                               save_to=V('current_loss'))\n",
    "                  .update_variable('loss_history', \n",
    "                                   V('current_loss'), \n",
    "                                   mode='a')) << ds\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  -0.6376127:  43%|████▎     | 646/1500 [40:23<49:29,  3.48s/it]"
     ]
    }
   ],
   "source": [
    "# Training loop. Allows to see progress (value of loss)\n",
    "with tqdm(total=EPOCHS, smoothing=0.3) as pbar:\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        train_batch = train_pipeline.next_batch(3, n_epochs=None)\n",
    "        current_loss = train_pipeline.get_variable(\"current_loss\")\n",
    "        loss_history.append(current_loss)\n",
    "\n",
    "        pbar.set_description('Loss:{:12.7}'.format(current_loss))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss against iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iterations\"), plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, loss starts to plateau after just 45 minutes of training. Relatively high variance suggests that model can benefit from bigger batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Now, we want to check performance of our model on unseen part of the cubes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pipeline = (Pipeline()\n",
    "                 .load_component(src=[D('geometries'), D('labels')],\n",
    "                                 dst=['geometries', 'labels'])\n",
    "                 .crop(points=L(ds.sampler.truncate(low=0.9, expr=lambda p: p[:, 1], prob=0.1).sample, NUM_CROPS),\n",
    "                       shape=CROP_SHAPE)\n",
    "                 .load_cubes(dst='data_crops')\n",
    "                 .create_masks(dst='mask_crops')\n",
    "                 .rotate_axes(src=['data_crops', 'mask_crops'])\n",
    "                 .scale(mode='normalize', src='data_crops')\n",
    "                 .add_axis(src='mask_crops', dst='mask_crops')\n",
    "                 .import_model('ED', train_pipeline)\n",
    "                 .init_variable('result', init_on_each_run=list()) \n",
    "                 .predict_model('ED', \n",
    "                                fetches=['cubes', 'masks', 'predictions', 'loss'],\n",
    "                                make_data={'cubes': B('data_crops'), 'masks': B('mask_crops')}, \n",
    "                                save_to=V('result'), mode='a')\n",
    "                 ) << ds\n",
    "\n",
    "val_batch = val_pipeline.next_batch(3, n_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss is: ', val_pipeline.get_variable('result')[0][3])\n",
    "\n",
    "for cube in np.random.choice(NUM_CROPS, 5):\n",
    "    print(val_batch.indices[cube][:-10])\n",
    "    iline = 0\n",
    "    \n",
    "    img =            val_pipeline.get_variable('result')[0][0][cube, :, :, iline].T\n",
    "    masks =          val_pipeline.get_variable('result')[0][1][cube, :, :, iline, 0].T\n",
    "    predicted_mask = val_pipeline.get_variable('result')[0][2][cube, :, :, iline, 0].T\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(25, 10))\n",
    "\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].set_title('Clear image')\n",
    "    \n",
    "    ax[1].imshow(masks, cmap=\"Blues\")\n",
    "    ax[1].imshow(img, cmap=\"gray\", alpha=0.5)\n",
    "    ax[1].imshow(masks, cmap=\"Blues\", alpha=0.1)\n",
    "    ax[1].set_title('Target mask')\n",
    "\n",
    "    ax[2].imshow(predicted_mask)\n",
    "    ax[2].set_title('Predicted mask')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is way easier to analyse results when multiple crops are glued together in one big slide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = ds.make_grid(ds.indices[0], CROP_SHAPE, \n",
    "                  [2201, 2202], [0, 800], [100, 1300],\n",
    "                  strides=[1, 128, 128])\n",
    "\n",
    "print('Shape of grid:', ds.grid_info['grid_array'].shape)\n",
    "\n",
    "pred_pipeline = (Pipeline()\n",
    "                 .load_component(src=[D('geometries'), D('labels')],\n",
    "                                 dst=['geometries', 'labels'])\n",
    "                 .crop(points=L(D('grid_gen')),\n",
    "                       shape=CROP_SHAPE)\n",
    "                 .load_cubes(dst='data_crops')\n",
    "                 .create_masks(dst='mask_crops')\n",
    "                 .rotate_axes(src=['data_crops', 'mask_crops'])\n",
    "                 .scale(mode='normalize', src='data_crops')\n",
    "                 .add_axis(src='mask_crops')\n",
    "                 # Predictions\n",
    "                 .import_model('ED', train_pipeline)\n",
    "                 .init_variable('result_cubes', init_on_each_run=list())\n",
    "                 .init_variable('result_masks', init_on_each_run=list())\n",
    "                 .init_variable('result_preds', init_on_each_run=list())\n",
    "                 .predict_model('ED', \n",
    "                                fetches=['cubes', 'masks', 'predictions'],\n",
    "                                make_data={'cubes': B('data_crops'), 'masks': B('mask_crops')}, \n",
    "                                save_to=[V('result_cubes'), V('result_masks'), V('result_preds')], mode='e')\n",
    "                 .assemble_crops(src=V('result_cubes'), dst='assembled_cube',\n",
    "                                   grid_info=D('grid_info'), mode='avg')\n",
    "                 .assemble_crops(src=V('result_masks'), dst='assembled_mask',\n",
    "                                   grid_info=D('grid_info'), mode='avg')\n",
    "                 .assemble_crops(src=V('result_preds'), dst='assembled_pred',\n",
    "                                   grid_info=D('grid_info'), mode='max')\n",
    "                 ) << ds\n",
    "\n",
    "for _ in range(ds.grid_iters):\n",
    "    pred_batch = pred_pipeline.next_batch(1, n_epochs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to slow changes in data along ilines in any given cube, it might be a good idea to test our model against completely new cube. To begin with, we need to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_path_data =           '/notebooks/SEISMIC_DATA/CUBE_2/M_cube.hdf5'\n",
    "test_save_dir =              '/notebooks/tsimfer/SAVED/CUBE_2/'\n",
    "\n",
    "test_path_pc_saved =       test_save_dir + 'point_clouds.dill'   # path_data: point_clouds\n",
    "\n",
    "test_dsi = FilesIndex(path=[test_path_data], no_ext=True)\n",
    "test_ds = SeismicCubeset(test_dsi)\n",
    "\n",
    "test_paths_txt = {test_ds.indices[0]: glob('/notebooks/SEISMIC_DATA/CUBE_2/HORIZONTS/*.txt')}\n",
    "\n",
    "test_ds = (test_ds.load_geometries()\n",
    "                  .load_point_clouds(paths = test_paths_txt)\n",
    "                  .load_labels()\n",
    "                  .load_samplers())\n",
    "\n",
    "## ~ 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_ds = test_ds.make_grid(test_ds.indices[0], CROP_SHAPE, \n",
    "                            [201, 202], [0, 800], [100, 1300],\n",
    "                            strides=[1, 128, 128])\n",
    "\n",
    "print('Shape of grid:', test_ds.grid_info['grid_array'].shape)\n",
    "\n",
    "pred_pipeline = (Pipeline()\n",
    "                 .load_component(src=[D('geometries'), D('labels')],\n",
    "                                 dst=['geometries', 'labels'])\n",
    "                 .crop(points=L(D('grid_gen')),\n",
    "                       shape=CROP_SHAPE)\n",
    "                 .load_cubes(dst='data_crops')\n",
    "                 .create_masks(dst='mask_crops')\n",
    "                 .rotate_axes(src=['data_crops', 'mask_crops'])\n",
    "                 .scale(mode='normalize', src='data_crops')\n",
    "                 .add_axis(src='mask_crops')\n",
    "                 # Predictions\n",
    "                 .import_model('ED', train_pipeline)\n",
    "                 .init_variable('result_cubes', init_on_each_run=list())\n",
    "                 .init_variable('result_masks', init_on_each_run=list())\n",
    "                 .init_variable('result_preds', init_on_each_run=list())\n",
    "                 .predict_model('ED', \n",
    "                                fetches=['cubes', 'masks', 'predictions'],\n",
    "                                make_data={'cubes': B('data_crops'), 'masks': B('mask_crops')}, \n",
    "                                save_to=[V('result_cubes'), V('result_masks'), V('result_preds')], mode='e')\n",
    "                 .assemble_crops(src=V('result_cubes'), dst='assembled_cube',\n",
    "                                   grid_info=D('grid_info'), mode='avg')\n",
    "                 .assemble_crops(src=V('result_masks'), dst='assembled_mask',\n",
    "                                   grid_info=D('grid_info'), mode='avg')\n",
    "                 .assemble_crops(src=V('result_preds'), dst='assembled_pred',\n",
    "                                   grid_info=D('grid_info'), mode='max')\n",
    "                 ) << test_ds\n",
    "\n",
    "for _ in range(test_ds.grid_iters):\n",
    "    pred_batch = pred_pipeline.next_batch(1, n_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_full = pred_batch.assembled_cube\n",
    "pred_full = pred_batch.assembled_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(25, 25))\n",
    "ax[0].imshow(img_full[0, :, :].T, cmap='gray')\n",
    "ax[1].imshow(pred_full[0, :, :].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is time to save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/notebooks/SEISMIC_DATA/SAVED/MODELS/'\n",
    "name = 'ED'\n",
    "\n",
    "dir_ = save_dir + name + '/'\n",
    "try:\n",
    "    os.mkdir(dir_)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "def _convert(config):\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            _convert(value)\n",
    "        else:\n",
    "            config[key] = str(value)\n",
    "\n",
    "_convert(pipeline_config)\n",
    "with open(dir_+'config.json', 'w') as f:\n",
    "    json.dump(pipeline_config, f)\n",
    "\n",
    "\n",
    "train_pipeline.save_model('ED', dir_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='criticism'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticism\n",
    "\n",
    "Currently, model evalution is not fully automated: making one big script to get single number is instrumental in model analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='suggestions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggestions for improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* add non-regular grid for assemble_crops\n",
    "\n",
    "* improve conventions inside of the assemble_grid\n",
    "\n",
    "* make whole end-to-end pipeline of model evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
